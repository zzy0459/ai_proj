import os
import time
import re
import textwrap
from typing import List, Tuple, Dict, Any
from openai import OpenAI
from func_timeout import func_timeout, FunctionTimedOut

# é…ç½®å‚æ•°ï¼ˆå®Œå…¨ä¿ç•™ï¼‰
TAILLARD_DIR = 'TestSolutions/taillard'
MAX_ITERATIONS = 8
POPULATION_SIZE = 10
MAX_RETRIES = 5
BASE_DELAY = 1.2
SCHEDULER_REGEX = r'^def scheduler\(instance\):[\s\S]*?return schedule$'

def safe_exec(code: str, instance: dict) -> List[Tuple[int, int]]:
    local_env = {}
    try:
        safe_builtins = {
            'range': range,
            'len': len,
            'min': min,
            'max': max,
            'sum': sum,
            'sorted': sorted,
            'enumerate': enumerate,
            'zip': zip,
            'map': map,
            'filter': filter,
            'list': list,
            'float': float,  # æ–°å¢floatå‡½æ•°
        }
        exec(code, {"__builtins__": safe_builtins}, local_env)
        if 'scheduler' not in local_env:
            raise RuntimeError("æœªå®šä¹‰ scheduler å‡½æ•°")
        return local_env['scheduler'](instance)
    except Exception as e:
        raise RuntimeError(f"æ‰§è¡Œé”™è¯¯: {e}")

# === ä»¥ä¸‹ä¸ºå®Œå…¨ä¿ç•™çš„åŸå§‹ä»£ç ï¼ˆå…±308è¡Œï¼‰===
def load_taillard_instance(file_path: str) -> Dict:  # ä¿ç•™æ‰€æœ‰ä»£ç 
    """
    è§£ææµæ°´è½¦é—´(Flow Shop)æ ¼å¼çš„Taillardæ•°æ®ã€‚
    """
    try:
        with open(file_path, 'r') as f:
            lines = [line.strip() for line in f if line.strip()]
            num_jobs, num_machines = map(int, lines[0].split())
            processing_times = []
            for m in range(num_machines):
                data = list(map(int, lines[m + 1].split()))
                if len(data) != num_jobs:  # ä¿ç•™æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
                    print(f"æœºå™¨ {m + 1} æ•°æ®ä¸å®Œæ•´ï¼ŒæœŸæœ› {num_jobs} ä¸ªä½œä¸šï¼Œå®é™… {len(data)} ä¸ª")
                    return None
                processing_times.append(data)
            job_processing = [
                [processing_times[m][j] for m in range(num_machines)]
                for j in range(num_jobs)
            ]
            machine_orders = [[m for m in range(num_machines)] for _ in range(num_jobs)]
            return {
                'num_jobs': num_jobs,
                'num_machines': num_machines,
                'processing_times': job_processing,
                'machine_orders': machine_orders
            }
    except Exception as e:  # ä¿ç•™åŸå§‹å¼‚å¸¸å¤„ç†
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def calculate_makespan(schedule: List[Any], instance: Dict) -> int:  # å®Œæ•´ä¿ç•™
    """
    è®¡ç®—è°ƒåº¦æ–¹æ¡ˆçš„ makespanã€‚
    éªŒè¯æ¯ä¸ªä½œä¸šçš„å·¥åºä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œï¼Œå¹¶è¿”å›æ€»å®Œå·¥æ—¶é—´ã€‚
    """
    num_jobs = instance['num_jobs']
    num_machines = instance['num_machines']
    processing_times = instance['processing_times']
    machine_orders = instance['machine_orders']

    machine_times = [0] * num_machines
    job_finish = [0] * num_jobs
    next_op = [0] * num_jobs

    for idx, step in enumerate(schedule):
        if not (hasattr(step, '__getitem__') and len(step) >= 2):  # ä¿ç•™æ ¼å¼æ£€æŸ¥
            print(f"ç´¢å¼• {idx} å¤„çš„è°ƒåº¦æ­¥éª¤æ ¼å¼é”™è¯¯: {step}")
            return float('inf')
        job, op = step[0], step[1]
        if not (0 <= job < num_jobs) or not (0 <= op < num_machines):  # ä¿ç•™è¾¹ç•Œæ£€æŸ¥
            print(f"æ­¥éª¤ {idx} éæ³•ä½œä¸šIDæˆ–å·¥åºå·: {step}")
            return float('inf')
        if op != next_op[job]:  # ä¿ç•™å·¥åºé¡ºåºæ£€æŸ¥
            print(f"æ­¥éª¤ {idx} å·¥åºé¡ºåºé”™è¯¯: ä½œä¸š {job} é¢„æœŸ {next_op[job]}ï¼Œå®é™… {op}")
            return float('inf')
        machine = machine_orders[job][op]
        proc_time = processing_times[job][op]
        start_time = max(job_finish[job], machine_times[machine])
        finish_time = start_time + proc_time
        machine_times[machine] = finish_time
        job_finish[job] = finish_time
        next_op[job] += 1

    if any(next_op[j] != num_machines for j in range(num_jobs)):  # ä¿ç•™å®Œæ•´æ€§æ£€æŸ¥
        print("éƒ¨åˆ†ä½œä¸šæœªå®Œæˆæ‰€æœ‰å·¥åº")
        return float('inf')
    return max(machine_times)

def evaluate_program(program_code: str, instance: Dict) -> Tuple[int, str]:
    lines = program_code.splitlines()
    clean_lines = [l for l in lines if not l.strip().startswith('```')]
    clean_code = '\n'.join(clean_lines)

    func_match = re.search(r'(def scheduler\s*\([^)]*\):[\s\S]*?\breturn\s+schedule)', clean_code)
    if not func_match:
        return float('inf'), "æœªæ‰¾åˆ°å®Œæ•´çš„ scheduler å®šä¹‰æˆ– return schedule"
    func_def = func_match.group(1)

    body_match = re.search(r'def scheduler\s*\([^)]*\):(.*)', func_def, re.S)
    if not body_match:
        return float('inf'), "æ— æ³•è§£æå‡½æ•°ä½“ç»“æ„"
    body = textwrap.dedent(body_match.group(1))
    indented = ''.join('    ' + line + '\n' for line in body.splitlines())
    new_code = f"def scheduler(data):\n{indented}    return schedule\n"

    # === å…³é”®ä¿®å¤ï¼šä½¿ç”¨å®Œæ•´çš„ safe_builtins ===
    safe_builtins = {
        'range': range,
        'len': len,
        'min': min,
        'max': max,
        'sum': sum,
        'sorted': sorted,
        'enumerate': enumerate,
        'zip': zip,
        'map': map,
        'filter': filter,
        'list': list,
        'float': float,  # æ–°å¢float
    }
    restricted_globals = {
        '__builtins__': safe_builtins,
        'instance': instance['processing_times'],
        '__name__': '__main__'
    }
    # === ä¿®å¤ç»“æŸ ===

    try:
        exec(new_code, restricted_globals)
    except Exception as e:
        return float('inf'), f"ç¼–è¯‘é”™è¯¯: {e}"

    def safe_exec_wrapper():
        scheduler = restricted_globals['scheduler']
        schedule = scheduler(restricted_globals['instance'])
        if not isinstance(schedule, list):
            raise TypeError("è°ƒåº¦ç»“æœå¿…é¡»ä¸ºåˆ—è¡¨ç±»å‹")
        return schedule

    try:
        schedule = func_timeout(15, safe_exec_wrapper)  # 5ç§’è¶…æ—¶
    except FunctionTimedOut:
        return float('inf'), 'ä»£ç æ‰§è¡Œè¶…æ—¶ï¼ˆ5ç§’ï¼‰'  # æ˜ç¡®è¶…æ—¶æ—¶é—´
    except Exception as e:
        return float('inf'), f"æ‰§è¡Œé”™è¯¯: {e}"

    import io, contextlib
    buf = io.StringIO()
    try:
        with contextlib.redirect_stdout(buf):
            makespan = calculate_makespan(schedule, instance)
    except Exception as e:
        debug = buf.getvalue().strip()
        reason = f"éªŒè¯æ—¶å¼‚å¸¸: {e}"
        if debug:
            reason += f" | è¾“å‡º: {debug}"
        return float('inf'), reason
    debug_output = buf.getvalue().strip()
    if makespan == float('inf'):
        reason = debug_output or 'æœªçŸ¥éªŒè¯é”™è¯¯'
        return makespan, reason
    return makespan, None

class DashScopeLLM:
    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        self.model = "qwen-max-latest"
        self.temperature = 0.7

    def generate(self, prompt: str) -> str:
        """å¢å¼ºç‰ˆç”Ÿæˆå‡½æ•°ï¼ŒåŒ…å«è¯¦ç»†è¯Šæ–­æ—¥å¿—"""
        prompt += f"\n\n# æ ¼å¼è¦æ±‚ï¼š{SCHEDULER_REGEX}"
        for attempt in range(MAX_RETRIES):
            print(f"\n=== APIå°è¯• {attempt+1}/{MAX_RETRIES} ===")
            print(f"å½“å‰æç¤ºé•¿åº¦ï¼š{len(prompt)} å­—ç¬¦")
            print("æç¤ºå†…å®¹ï¼ˆå‰100å­—ç¬¦ï¼‰ï¼š", prompt[:100] + ("..." if len(prompt) > 100 else ""))

            try:
                start = time.time()
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ä¸¥æ ¼æŒ‰ç”¨æˆ·è¦æ±‚ç”Ÿæˆschedulerå‡½æ•°ï¼Œä¸æ·»åŠ é¢å¤–å†…å®¹"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.temperature,
                    max_tokens=1000,
                    timeout=30  # APIè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
                )
                duration = time.time() - start
                print(f"âœ… APIæˆåŠŸå“åº”ï¼ˆè€—æ—¶{duration:.2f}sï¼‰")

                # æå–ç”Ÿæˆå†…å®¹
                generated = response.choices[0].message.content.strip()
                print(f"ç”Ÿæˆä»£ç ï¼ˆå‰50å­—ç¬¦ï¼‰ï¼š{generated[:50]}...ï¼ˆæ€»é•¿åº¦{len(generated)}ï¼‰")

                # æ ¼å¼éªŒè¯
                if re.match(SCHEDULER_REGEX, generated, re.MULTILINE):
                    print("âœ… ä»£ç æ ¼å¼åŒ¹é…æ­£åˆ™")
                    return generated
                else:
                    print("âŒ æ ¼å¼é”™è¯¯ï¼šæœªåŒ¹é…schedulerå‡½æ•°æ­£åˆ™")
                    print("ç”Ÿæˆå†…å®¹å¼€å¤´ï¼š", generated[:100])  # æ‰“å°å¼€å¤´å¸®åŠ©å®šä½
                    return None

            except FunctionTimedOut:
                print("â—ï¸ é”™è¯¯ï¼šAPIè°ƒç”¨è¶…æ—¶ï¼ˆ30ç§’æœªå“åº”ï¼‰")
                print("ç½‘ç»œå¯èƒ½ä¸ç¨³å®šï¼Œæˆ–æ¨¡å‹å¤„ç†æ—¶é—´è¿‡é•¿")
            except Exception as e:
                print(f"â—ï¸ é”™è¯¯ï¼šAPIè¯·æ±‚å¤±è´¥ - {type(e).__name__}")
                print("è¯¦ç»†ä¿¡æ¯ï¼š", str(e))
                # æ‰“å°å®Œæ•´å †æ ˆè·Ÿè¸ªï¼ˆè°ƒè¯•ç”¨ï¼‰
                import traceback
                traceback.print_exc()

            # è®¡ç®—å¹¶æ˜¾ç¤ºé‡è¯•å»¶è¿Ÿ
            delay = BASE_DELAY ** attempt
            print(f"â³ ç¬¬{attempt+1}æ¬¡é‡è¯•å»¶è¿Ÿï¼š{delay:.1f}ç§’")
            time.sleep(delay)

        print("âŒ æ‰€æœ‰APIå°è¯•å¤±è´¥ï¼Œè¿”å›ç©º")
        return None

class FunSearch:
    def __init__(self, instance: Dict):
        self.instance = instance
        self.llm = DashScopeLLM()
        self.programs_db: List[Tuple[str, float]] = []
        self.error_history: List[str] = []
        initial_program = self._create_initial_program()
        score, err = evaluate_program(initial_program, instance)
        if err:
            print(f"åˆå§‹ç¨‹åºè¯„ä¼°é”™è¯¯: {err}")
            self.error_history.append(err)
        self.programs_db.append((initial_program, score))
    def _create_initial_program(self) -> str:
            """ä½¿ç”¨NEHå¯å‘å¼ç”Ÿæˆåˆå§‹è§£ï¼šæŒ‰æ€»å¤„ç†æ—¶é—´é™åºæ’åº"""
            return f"""
    def scheduler(instance):
        # 1. è®¡ç®—æ¯ä¸ªä½œä¸šçš„æ€»å¤„ç†æ—¶é—´
        job_total_time = [sum(task_times) for task_times in instance]
        # 2. æŒ‰æ€»æ—¶é—´é™åºæ’åºä½œä¸š
        jobs = sorted(range(len(instance)), key=lambda j: -job_total_time[j])
        # 3. ç”Ÿæˆé¡ºåºè°ƒåº¦ï¼ˆä½œä¸šæŒ‰é¡ºåºï¼Œå·¥åºæŒ‰æœºå™¨é¡ºåºï¼‰
        schedule = []
        for job in jobs:
            for op in range(len(instance[0])):  # å·¥åº0åˆ°num_machines-1
                schedule.append((job, op))
        return schedule
    """

    def _build_prompt(self) -> str:
        """åŒ…å«è°ƒåº¦ç†è®ºçš„è¯¦ç»†æç¤º"""
        error_str = "\n".join([f"- {e}" for e in self.error_history[-3:]]) or "æ— è¿‘æœŸé”™è¯¯"

        return f"""
    # é‡è¦ï¼šè¯·åŸºäºä»¥ä¸‹è°ƒåº¦ä¼˜åŒ–ç­–ç•¥ç¼–å†™ä»£ç ï¼š
    1. **ä¼˜å…ˆè§„åˆ™**ï¼šä½¿ç”¨LPTï¼ˆé•¿ä½œä¸šä¼˜å…ˆï¼‰è§„åˆ™ï¼Œå…ˆå¤„ç†æ€»å¤„ç†æ—¶é—´é•¿çš„ä½œä¸š
    2. **æ’å…¥ç­–ç•¥**ï¼šå¯¹äºæ¯ä¸ªä½œä¸šï¼Œæ‰¾åˆ°æ’å…¥åmakespanæœ€å°çš„ä½ç½®ï¼ˆç±»ä¼¼NEHç®—æ³•ç¬¬äºŒæ­¥ï¼‰
    3. **å·¥åºçº¦æŸ**ï¼šæ¯ä¸ªä½œä¸šçš„å·¥åºå¿…é¡»æŒ‰0â†’1â†’...â†’(machines-1)é¡ºåºï¼Œä¸å¾—è·³è·ƒ
    4. **æ•°æ®è®¿é—®**ï¼šinstance[j][op]è¡¨ç¤ºä½œä¸šjåœ¨å·¥åºopçš„å¤„ç†æ—¶é—´

    # å½“å‰æœ€ä½³makespan: {min(s for _, s in self.programs_db)}
    # æœ€è¿‘é”™è¯¯ï¼ˆæœ€å¤š3æ¡ï¼‰:
    {error_str}

    # å½“å‰ä»£ç ï¼ˆéœ€ä¼˜åŒ–ï¼‰:
    {self.programs_db[0][0]}

    è¯·è¾“å‡ºæ”¹è¿›çš„schedulerå‡½æ•°ï¼Œè¦æ±‚åŒ…å«æ’åºå’Œæ’å…¥é€»è¾‘ä»¥æœ€å°åŒ–makespanã€‚
    """

    def _update_population(self, code: str, score: float):
        if code in (c for c, _ in self.programs_db):
            print("é‡å¤ç¨‹åºï¼Œè·³è¿‡")
            return
        self.programs_db.append((code, score))
        self.programs_db.sort(key=lambda x: x[1])
        self.programs_db = self.programs_db[:POPULATION_SIZE]

    def evolve(self):
        for i in range(MAX_ITERATIONS):
            print(f"\n{'=' * 10} è¿­ä»£ {i + 1}/{MAX_ITERATIONS} {'=' * 10}")
            current_best = min(score for _, score in self.programs_db)
            print(f"â–¶ å½“å‰æœ€ä½³: {current_best}")

            # æ„å»ºå¹¶æ˜¾ç¤ºæç¤ºæ‘˜è¦
            prompt = self._build_prompt()
            print("\nğŸ“ æç¤ºæ‘˜è¦ï¼ˆå‰300å­—ç¬¦ï¼‰:")
            print(prompt[:300].replace('\n', ' ') + "..." if len(prompt) > 300 else prompt)

            # ç”Ÿæˆä»£ç 
            new_code = self.llm.generate(prompt)
            if not new_code:
                print("ğŸš« æ— æœ‰æ•ˆä»£ç ï¼Œè·³è¿‡æœ¬æ¬¡è¿­ä»£")
                continue

            # å¼ºåˆ¶æ‰“å°å®Œæ•´ç”Ÿæˆä»£ç ï¼ˆç”¨åˆ†éš”ç¬¦æ˜æ˜¾åŒºåˆ†ï¼‰
            print("\n=== ç”Ÿæˆçš„å®Œæ•´ä»£ç å¼€å§‹ ===")
            print(new_code)
            print("=== ç”Ÿæˆçš„å®Œæ•´ä»£ç ç»“æŸ ===\n")

            # æ‰§è¡Œè¯„ä¼°å¹¶è®¡æ—¶
            start = time.perf_counter()
            score, err = evaluate_program(new_code, self.instance)
            duration = time.perf_counter() - start

            if err:
                # è§£æè¶…æ—¶ç±»å‹ï¼ˆAPIè¶…æ—¶ vs ä»£ç æ‰§è¡Œè¶…æ—¶ï¼‰
                if 'ä»£ç æ‰§è¡Œè¶…æ—¶' in err:
                    print(f"â° æ‰§è¡Œè¶…æ—¶: ä»£ç è¿è¡Œè¶…è¿‡5ç§’ï¼ˆè€—æ—¶{duration:.2f}sï¼‰")
                else:
                    print(f"âŒ æ‰§è¡Œé”™è¯¯: {err}ï¼ˆè€—æ—¶{duration:.2f}sï¼‰")
                self.error_history.append(f"{err} (ä»£ç é•¿åº¦{len(new_code)})")
            else:
                print(f"âœ… è¯„ä¼°é€šè¿‡: makespan={score}ï¼ˆè€—æ—¶{duration:.2f}sï¼‰")
                if score < current_best:
                    print("ğŸ‰ æ–°æœ€ä½³è§£ï¼")

            self._update_population(new_code, score)
            print(f"ğŸ”„ ç§ç¾¤å½“å‰æœ€ä¼˜: {min(s for _, s in self.programs_db)}\n")

def main():
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")
        return
    path = os.path.join(TAILLARD_DIR, 'ta062.dat')
    inst = load_taillard_instance(path)
    if not inst:
        return
    fs = FunSearch(inst)
    fs.evolve()
    best_code, best_score = min(fs.programs_db, key=lambda x: x[1])
    print(f"\næœ€ä½³ makespan: {best_score}")
    print("æœ€ä½³ç¨‹åºä»£ç :")
    print(best_code)

if __name__ == "__main__":
    main()